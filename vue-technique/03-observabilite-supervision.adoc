= Observabilité et supervision

== Objectifs

Garantir la capacité à superviser l'ensemble des composants de la plateforme Beep, à diagnostiquer rapidement les anomalies et à comprendre les comportements utilisateurs, est un prérequis essentiel pour assurer une exploitation de qualité et une expérience utilisateur optimale.

L’observabilité du système repose sur plusieurs dimensions complémentaires :

- la journalisation des événements et des flux techniques (logs),
- la traçabilité distribuée des requêtes (traces),
- la collecte et l’analyse de métriques métier et techniques (metrics),
- l'intégration avec les outils de supervision existants (SOC/SEIM entreprise).

== Architecture d'observabilité

Le dispositif d’observabilité de Beep s’appuie sur une stack open-source cohérente et éprouvée, déployée sur le cluster Kubernetes de production.

[mermaid]
----
graph TD
    subgraph K8s Cluster
        nginx[Ingress Nginx]
        istio[Istio Service Mesh]
        svc_auth[Auth Service]
        svc_user[User Management]
        svc_server[Server Management]
        svc_channel[Channel Service]
        svc_msg[Messaging Service]
        svc_notif[Notification Service]
        svc_search[Search Service]
        svc_mod[Moderation Service]
        grafana[Grafana]
        prom[Prometheus]
        loki[Grafana Loki]
        tempo[Grafana Tempo]
        es[ElasticSearch (SOC)]
    end

    istio --> prom
    istio --> tempo
    svc_auth --> loki
    svc_user --> loki
    svc_server --> loki
    svc_channel --> loki
    svc_msg --> loki
    svc_notif --> loki
    svc_search --> loki
    svc_mod --> loki

    grafana --> prom
    grafana --> tempo
    grafana --> loki
    grafana --> es
----

Les composants clés sont :

- **Prometheus** pour la collecte de métriques (techniques et métier)
- **Grafana Tempo** pour le tracing distribué (basé sur OpenTelemetry)
- **Grafana Loki** pour la journalisation centralisée des logs
- **Grafana** comme point d’entrée pour l’observabilité unifiée
- **ElasticSearch** pour l'archivage long terme des logs et leur exposition vers le SIEM / SOC.

Le maillage réseau assuré par **Istio** (mutual TLS activé) permet une instrumentation automatique et homogène de la majorité des flux inter-services, facilitant la collecte des traces et métriques.

== Journalisation centralisée (Logs)

Chaque microservice produit des logs structurés au format JSON, enrichis avec les métadonnées nécessaires :

- identifiants de trace (trace_id, span_id)
- identifiants utilisateur
- identifiants métier (serveur, canal, message, etc.)
- contexte d'exécution (environnement, version de service)

Les logs sont agrégés via **Loki** pour une analyse en temps réel, avec rétention courte (15 jours) pour l’exploitation courante, et archivage plus long (ElasticSearch) pour les besoins de conformité et de forensique.

Les événements de sécurité critiques (authentification, tentatives d'attaque, modification de rôles, suppressions sensibles…) sont systématiquement exportés vers le **SIEM** de l’entreprise.

== Traces distribuées

Les flux utilisateur impliquent souvent plusieurs microservices en cascade. Afin de comprendre et d’optimiser ces parcours, tous les appels inter-services sont tracés via **OpenTelemetry**, avec Tempo en backend.

Chaque requête reçoit un identifiant de trace global propagé tout au long de son cycle de traitement, permettant :

- d’identifier les goulots d’étranglement,
- de mesurer la latence de bout en bout,
- de diagnostiquer rapidement les anomalies de performance.

Les traces sont visualisables via Grafana, et corrélées avec les logs et métriques pour une analyse complète.

== Supervision technique et métier (Metrics)

Chaque service expose des métriques Prometheus en natif (via Istio sidecar ou instrumentation spécifique).

Les métriques collectées couvrent plusieurs aspects :

- **Métriques système** : CPU, mémoire, usage réseau
- **Métriques applicatives** : nombre de requêtes, latence par endpoint, taux d'erreurs
- **Métriques métier** : nombre de serveurs créés, nombre de messages envoyés, taux de rétention des utilisateurs, volume de notifications traitées…

Des tableaux de bord Grafana permettent aux équipes :

- de surveiller la santé des services,
- de suivre les indicateurs métier clés,
- d'anticiper les besoins de scaling.

== Exemple de flux observable : Envoi de message

[mermaid]
----
sequenceDiagram
    participant Client
    participant Gateway
    participant Auth
    participant Messaging
    participant Notifications
    participant Loki
    participant Tempo
    participant Prometheus

    Client->>Gateway: POST /channels/:id/messages
    Gateway->>Auth: Validate JWT
    Gateway->>Messaging: POST /messages
    Messaging->>Messaging: Store message
    Messaging->>Notifications: Emit new_message

    Note over Gateway,Messaging: Trace_id propagé

    Messaging->>Loki: Log message
    Messaging->>Tempo: Trace span
    Messaging->>Prometheus: Increment metric
    Notifications->>Loki: Log notification
    Notifications->>Tempo: Trace span
----

== Intégration SOC et sécurité des logs

Le dispositif d'observabilité est directement relié au SOC de l’entreprise :

- Les logs de sécurité sont forwardés en temps réel vers **ElasticSearch** / SIEM.
- Des alertes automatiques sont configurées pour les événements sensibles :
  - tentatives de connexion suspectes,
  - anomalies de comportement,
  - patterns de scan ou d’attaque,
  - élévation de privilèges anormale.

== Conclusion

L’architecture d’observabilité de Beep repose sur des standards ouverts et des solutions éprouvées, garantissant :

- une **visibilité complète** du système, à tous les niveaux,
- une **traçabilité complète** pour les besoins de conformité,
- une capacité à diagnostiquer et résoudre rapidement les incidents,
- un alignement avec les pratiques de supervision de l’entreprise.

Elle constitue un levier clé pour garantir la qualité de service, la sécurité, et l’évolutivité de la plateforme.

